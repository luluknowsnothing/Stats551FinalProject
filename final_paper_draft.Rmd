---
title: "Why do people misperceive their ability relative to others? An examination using Bayesian statistics"
author: "Yuyan Han & Qinggang Yu"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: yes
  pdf_document:
    df_print: kable
    latex_engine: xelatex
    toc: yes
bibliography: mybib.bib
documentclass: article
fontsize: 12pt
geometry: margin=1in
link-citations: yes
mainfont: Times New Roman
csl: ASA.csl
sansfont: Times New Roman
subtitle: STATS 551 Final paper
always_allow_html: yes
---

\pagebreak

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 6, fig.height = 3)
library(knitr)
library(tidyverse)
library(xlsx)
library(lmerTest)
library(emmeans)
```

# Introduction

Most people do not have accurate perception of their self-knowledge. Prior work has documented the Dunning-Kruger effect, which suggests that across multiple domains, bottom-performers overestimate their performance, while top-performers tend to underestimate their performance. Such an effect also happens when people judge their performance relative to others: bottom-performers overestimate their ranking in terms of performance, yet top-performers underestimate. 

So far, it remains unclear what contributes to this miscalibration in social comparison. To explain this miscalibration, psychologists have done extensive investigation in how people perceive (or misperceive) their absolute ability on different tasks. However, much less is known about how people perceive (or misperceive) the ability of others, which intuitively should play an important role in social comparison. In a typical survey, respondents are asked to pick the best answers for a set of multiple-choice questions, rate their confidence in each pick, and rank their performance relative to others in percentile. Oftentimes we do not have information on how respondents make specific estimations about others‚Äô performance, which hinders our understandings of how people perceive others and how this interacts with people's biased rating in social comparison.    

In the present study, we therefore collect data on people's perception of others' performance in addition to a typical survey, and attempt to tackle the issue by first gaining some insights into how people perceive others' performance using Bayesian statistics. Specifically, we examine the possibility that people use the self as an anchor when judging others. Importantly, we test whether the degree that people use the self as an anchor varies as a function of their perceived their ability relative to others.  

We propose that when making an inference about other's performance on a specific task, people will use three sources of information, (a) their perception of their own performance on the task, (b) their perception of their overall ability relative to others, and (c) some random guessing or bias in their inference.  

Specifically, we are interested in testing the role of a particular cognitive bias, namely the curse of knowledge, which refers to the phenomenon that when people feel knowledgeable about something, they tend to unknowingly assume that others know it too. To demonstrate, for a given individual, will she perceive higher consensus when she has higher confidence? Across individuals, will those who perceive themselves being more knowledgeable relative to others show a greater curse of knowledge by assuming a higher correlation between their own confidence and others' consensus?


# Data

We used three separate datasets to test our prediction, which were collected using Amazon Mechanical Turk in the year of 2017 and 2018. Each of the datasets was generated by having multiple subjects answering a number of multiple-choice questions. For each question, subjects were asked to (1) picked the best choice for the question as they believed; (2) rated their beliefs, in percentage, that each choice was the correct answer; (3) estimated the percentage of other respondents who would pick each choice as the correct answer. The probabilities assigned to each choice of a question should sum up to 1 for both (2) and (3).  
Here is a sample question:  
‚ÄúNew employees must be offered insurance within____ days of their start date.  
A. 60 days; B. 90 days.  
What do you think is the probability of each choice being the correct answer?  
What percentage of MTurk workers taking this survey do you think will choose each choice as the correct answer?‚Äù  

At the end of the study, subjects were asked to provide an estimate of their performance compared to others using percentile. 

The first dataset was generated using 18 two-alternative multiple-choice questions on the topic of Affordable Care Act. This dataset contains 74 subjects. The second dataset was generated using 12 four-alternative multiple-choice questions of the Raven‚Äôs Advanced Progressive Matrix, a test of abstract reasoning. This dataset contains 91 subjects. The third dataset was generated using 16 four-alternative multiple-choice questions on global geography, international systems etc. This dataset contains 172 subjects.

# Model

Following our theoretical questions, we therefore constructed a two-level model to test this cognitive bias. (1) Whether their perceived consensus is positively correlated with their own confidence, such that when they are more confidence  there a positive correlation confident in  if the strength of the relationship between Y and X further varies as a function of the person's belief about his or her own overall ability in this domain relative to others, $\theta$. This is due to a well-studied cognitive bias, **curse of knowledge**, that top performers in particular tend to assume other people share the same degree of expertise they themselves have, hence overestimate the similarity between the self and the others. Therefore, we aim to test if Y is also predicted by the interaction between X and $\theta$.


the item response theory (IRT) to approach this question. We assume that the probability that a respondent believes that another person will choose the same answer for an item, denoted as Y,  is a mathematical function of the person and items. In this case, the person trait refers to the respondent‚Äôs beliefs about their ranking relative to others, denoted as Œ∏p, and a general perceived similarity between themselves and others, denoted as ùõº; the item trait refers to respondent‚Äôs confidence on specific items, denoted as X, and respondent‚Äôs level of performance Z	. 
Taking the performance on a multiple-choice question in a test as an example. A person believes that choice C is the correct answer with some confidence X, and the person believes that Y percent of people will consent on choice C being the correct answer. We propose that Y is determined by X, such that the person determines how many other people would choose the same answer based on the certainty of his or her own choice. Y should also be influenced by a certain degree of random guessing of what others would do (i.e., if there are 4 choices, by pure chance along, 25% of other people would choose C as the correct answer). We are interested in testing if the strength of the relationship between Y and X further varies as a function of the person's belief about his or her own overall ability in this domain relative to others, $\theta$. This is due to a well-studied cognitive bias, **curse of knowledge**, that top performers in particular tend to assume other people share the same degree of expertise they themselves have, hence overestimate the similarity between the self and the others. Therefore, we aim to test if Y is also predicted by the interaction between X and $\theta$.

We built a multilevel regression model using the Bayesian framework with each of the datasets. Our data can be organized into two levels. Each subject answered a number of questions (18, 12, 16, respectively in our study), which constitutes the item-level. For each question, the subject rated the confidence that the option he/she selected was correct, and the subject provided an estimate of the percentage of other people who would choose the same option. We fit a linear regression at the item-level (across the items within each subject) as follows:  


where $\epsilon_{pi}$ represents the error term for item i of subject p, and  $\beta_0$ and $\beta_1$ represents the random intercept and the random slope, respectively, which are allowed to vary across subjects.  
$\beta_1$, in particular, represents the strength of the relationship between one's confidence of his/her own choice and his/her belief on how many other people would choose the same option. We thus fit a linear regression at the subject-level to see if this relationship depends on one's belief about the overall ablity of the self relative to others, represented as $\theta$:





## Data collection

### Twitter data

The data of the present study were collected by live-streaming tweets during a three-week period from October 30th to November 19th. We targeted this period because it overlapped with the onset of the "third wave" of the COVID-19 pandemic in the U.S., when close to 2,700,000 new cases and more than 22,000 new deaths happened. All tweets were from within the U.S. as we applied a bounding box defined by geographical coordinates of the U.S borders during tweet streaming. We conducted two separate lines of collection. One collection streamed tweets containing words that are related to the COVID-19 pandemic, such as "covid", "corona", and "pandemic" (for the full list, see below). The other collection streamed general tweets, which means we did not limit the collection to any specific keywords. This general collection provides an estimate of the baseline sentiment pattern.

```{r covid list, eval = FALSE}
COVID_list <- c('covid', 'corona', 'pandemic', 'epidemic',
                'reopen', 'quarantine','social distance', 
                'cough', 'fever', 'mask', 'virus', 'infect',
                'contagious', 'stayhome')
```


